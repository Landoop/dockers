#!/usr/bin/env bash

RED='\033[0;31m'
NC='\033[0m' # No Color

set -o nounset \
    -o errexit \
    -o verbose \
    -o xtrace

function WriteFiles() {
  PROVIDER=$1
  if [[ -z "$PROVIDER" ]]; then 
    PROVIDER=env
  fi

  /opt/lenses/bin/lenses-cli \
    secrets \
    connect \
    ${PROVIDER} \
    --secret-file "/etc/kafka-connect/secrets.properties" \
    --connector-file "/etc/kafka-connect/connector.properties" \
    --worker-file "/etc/kafka-connect/kafka-connect.properties"
}

dub ensure CONNECT_BOOTSTRAP_SERVERS
dub ensure CONNECT_GROUP_ID
dub ensure CONNECT_CONFIG_STORAGE_TOPIC
dub ensure CONNECT_OFFSET_STORAGE_TOPIC
dub ensure CONNECT_STATUS_STORAGE_TOPIC
dub ensure CONNECT_KEY_CONVERTER
dub ensure CONNECT_VALUE_CONVERTER
dub ensure CONNECT_INTERNAL_KEY_CONVERTER
dub ensure CONNECT_INTERNAL_VALUE_CONVERTER
dub ensure CONNECT_REST_ADVERTISED_HOST_NAME
dub ensure CONNECT_REST_PORT
   
if [[ $CONNECT_INTERNAL_KEY_CONVERTER == "org.apache.kafka.connect.json.JsonConverter" ]] || [[ $CONNECT_INTERNAL_VALUE_CONVERTER == "org.apache.kafka.connect.json.JsonConverter" ]]
then
  export CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE=false
  export CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE=false
fi

if [[ $CONNECT_KEY_CONVERTER == "io.confluent.connect.avro.AvroConverter" ]]
then
   dub ensure CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL
fi

if [[ $CONNECT_VALUE_CONVERTER == "io.confluent.connect.avro.AvroConverter" ]]
then
   dub ensure CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL
fi

# The connect-distributed script expects the log4j config at /etc/kafka/connect-log4j.properties.
dub template "/etc/confluent/docker/log4j.properties.template" "/etc/kafka/connect-log4j.properties" 

# Call the Lenses CLI to create the files
dub ensure SECRETS_PROVIDER
WriteFiles "${SECRETS_PROVIDER,,}"